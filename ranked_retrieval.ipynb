{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from load_data_json import LoadDataset \n",
    "from preprocess import VectorSpaceModel\n",
    "from preprocess_restart import VectorSpaceModel2\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse.linalg import svds, eigsh\n",
    "import ipyparallel as ipp\n",
    "from scipy.sparse import diags\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the dataset\n",
    "Functions to load the dataset and the given queries with associated relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dungl\\anaconda3\\envs\\IR_VectorSpaceModel\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = LoadDataset(\"./data/med/med.json\", \"./data/med/queries.json\", \"./data/med/qrels-treceval.txt\",\"med\")\n",
    "# vsm = VectorSpaceModel(dataset.doc_matrix, dataset.name)\n",
    "vsm = VectorSpaceModel2(dataset.doc_matrix, dataset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisec_PDDP(A, iter = 4):\n",
    "        # if np.all(indices==None):\n",
    "        #     A = self.A\n",
    "        # elif self.left:\n",
    "        #     A = self.A[indices, :]\n",
    "        # else:\n",
    "        #     A = self.A[:, indices]\n",
    "        \n",
    "        m, n = A.shape\n",
    "\n",
    "        # if m < n:\n",
    "        #     d = np.sum(A, axis=0)/m\n",
    "        #     q = np.zeros((m, iter))\n",
    "        #     v = np.random.rand(m)\n",
    "        # else:\n",
    "\n",
    "        d = np.sum(A, axis=1)/n\n",
    "        q = np.zeros((n, iter+1))\n",
    "        v = np.random.rand(n)\n",
    "        \n",
    "        q[:,0] = v/np.linalg.norm(v)\n",
    "        d = np.array(d).flatten()\n",
    "        \n",
    "        # lanczos\n",
    "        alpha = np.zeros(iter+1)\n",
    "        beta = np.zeros(iter+1)\n",
    "        \n",
    "        for i in range(iter):\n",
    "            # if m < n:\n",
    "            #     q_hat = A.T @ q[:,i] - np.sum(q[:,i]) * d\n",
    "            #     w = A @ q_hat - beta[i] * q[:,i-1] - np.full(m, q_hat @ d)\n",
    "            # else:\n",
    "            q_hat = A @ q[:,i] - np.sum(q[:,i]) * d\n",
    "            w = A.T @ q_hat - beta[i] * q[:,i-1] - np.full(n, q_hat @ d)\n",
    "\n",
    "            alpha[i] = w.dot(q[:,i])\n",
    "            w = w - alpha[i] * q[:,i]\n",
    "\n",
    "            beta[i+1] = np.linalg.norm(w)\n",
    "            if beta[i+1] == 0:\n",
    "                break\n",
    "            q[:,i+1] = w / beta[i+1]\n",
    "        # end lanczos\n",
    "        T = diags([alpha, beta, beta], [0, -1, 1]).toarray()\n",
    "        w, v = eigsh(T)\n",
    "        principal = q.dot(v[:,0])\n",
    "\n",
    "       \n",
    "        lo_bound = np.quantile(principal,.45)\n",
    "        up_bound = np.quantile(principal,.55)\n",
    "        left = np.where(principal < up_bound)[0]\n",
    "        right = np.where(principal > lo_bound)[0]\n",
    "        return left, right\n",
    "        # if np.all(indices==None):\n",
    "        #     return left, right\n",
    "        # else:\n",
    "        #     return indices[left], indices[right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "l, r = bisec_PDDP(dataset.doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    4,    5,    6,    7,    9,   11,   15,   16,   17,   22,\n",
       "         24,   26,   27,   28,   29,   30,   31,   32,   33,   35,   38,\n",
       "         42,   44,   45,   48,   49,   50,   52,   55,   56,   62,   63,\n",
       "         65,   67,   73,   74,   75,   76,   81,   83,   85,   86,   87,\n",
       "         88,   91,   96,   99,  100,  101,  102,  103,  104,  105,  106,\n",
       "        109,  110,  111,  112,  113,  114,  115,  116,  117,  118,  119,\n",
       "        120,  121,  123,  124,  125,  131,  133,  135,  138,  139,  140,\n",
       "        145,  147,  148,  149,  150,  153,  156,  157,  158,  160,  173,\n",
       "        186,  187,  191,  199,  202,  203,  204,  215,  216,  217,  218,\n",
       "        219,  221,  223,  224,  225,  227,  228,  230,  237,  238,  239,\n",
       "        240,  241,  242,  244,  245,  246,  247,  248,  251,  252,  259,\n",
       "        260,  266,  267,  271,  272,  275,  278,  287,  292,  297,  302,\n",
       "        304,  305,  306,  307,  308,  309,  310,  311,  312,  313,  315,\n",
       "        316,  317,  318,  319,  320,  321,  322,  323,  324,  325,  326,\n",
       "        327,  328,  329,  330,  332,  337,  345,  347,  348,  349,  351,\n",
       "        352,  353,  354,  355,  356,  358,  360,  361,  362,  363,  364,\n",
       "        365,  367,  368,  369,  371,  373,  375,  376,  378,  379,  380,\n",
       "        382,  383,  384,  385,  386,  387,  388,  389,  390,  391,  392,\n",
       "        406,  408,  409,  410,  411,  412,  413,  414,  415,  417,  418,\n",
       "        419,  420,  421,  422,  438,  439,  440,  441,  442,  443,  444,\n",
       "        445,  446,  447,  448,  449,  451,  452,  453,  454,  455,  456,\n",
       "        457,  458,  459,  460,  461,  462,  463,  465,  466,  467,  482,\n",
       "        483,  484,  486,  487,  488,  489,  490,  491,  492,  493,  495,\n",
       "        497,  500,  513,  515,  517,  518,  519,  521,  523,  524,  525,\n",
       "        526,  527,  534,  536,  537,  544,  545,  546,  547,  548,  549,\n",
       "        550,  551,  552,  553,  554,  555,  557,  558,  559,  560,  561,\n",
       "        563,  564,  565,  566,  567,  568,  569,  570,  571,  572,  573,\n",
       "        574,  575,  576,  577,  578,  579,  580,  582,  583,  584,  585,\n",
       "        586,  587,  588,  589,  590,  591,  592,  593,  594,  596,  597,\n",
       "        598,  599,  600,  601,  602,  603,  604,  605,  606,  607,  608,\n",
       "        609,  610,  611,  612,  613,  614,  615,  616,  617,  618,  619,\n",
       "        620,  621,  622,  623,  624,  626,  630,  632,  634,  635,  645,\n",
       "        649,  654,  660,  661,  662,  672,  678,  683,  686,  687,  688,\n",
       "        689,  690,  691,  692,  693,  694,  695,  696,  697,  698,  700,\n",
       "        704,  705,  706,  708,  713,  718,  719,  724,  725,  739,  740,\n",
       "        742,  743,  744,  746,  750,  753,  758,  761,  767,  769,  770,\n",
       "        771,  772,  773,  774,  775,  776,  777,  778,  779,  780,  781,\n",
       "        782,  784,  785,  786,  787,  788,  789,  790,  791,  792,  794,\n",
       "        795,  796,  797,  798,  799,  800,  801,  802,  803,  804,  805,\n",
       "        806,  807,  808,  809,  810,  811,  812,  813,  814,  815,  816,\n",
       "        817,  818,  819,  820,  821,  825,  826,  829,  830,  831,  834,\n",
       "        837,  839,  840,  841,  843,  844,  845,  846,  847,  848,  852,\n",
       "        853,  857,  860,  862,  863,  864,  865,  866,  867,  868,  869,\n",
       "        870,  871,  872,  873,  874,  875,  876,  877,  878,  879,  880,\n",
       "        881,  882,  883,  884,  886,  887,  888,  889,  890,  891,  892,\n",
       "        893,  895,  896,  897,  901,  907,  913,  914,  915,  916,  917,\n",
       "        918,  919,  920,  921,  922,  923,  924,  925,  926,  927,  929,\n",
       "        931,  932,  943,  944,  945,  946,  947,  948,  949,  950,  951,\n",
       "        952,  953,  954,  956,  957,  961,  962,  968,  971,  981,  984,\n",
       "        986,  988,  989,  990,  991,  992,  993,  994,  995,  996,  997,\n",
       "        998,  999, 1000, 1001, 1002, 1003, 1005, 1006, 1009, 1013, 1018,\n",
       "       1019, 1022, 1026, 1028, 1030, 1031, 1032], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.0003274 , -0.0003274 , -0.0003274 , ..., -0.0003274 ,\n",
       "         -0.0003274 , -0.0003274 ],\n",
       "        [-0.00793646, -0.00793646,  0.04057048, ...,  0.02286208,\n",
       "         -0.00793646, -0.00793646],\n",
       "        [-0.00672568, -0.00672568,  0.04696494, ..., -0.00672568,\n",
       "         -0.00672568, -0.00672568],\n",
       "        ...,\n",
       "        [-0.00011589, -0.00011589, -0.00011589, ..., -0.00011589,\n",
       "         -0.00011589, -0.00011589],\n",
       "        [-0.00010179, -0.00010179, -0.00010179, ..., -0.00010179,\n",
       "         -0.00010179, -0.00010179],\n",
       "        [-0.00029107, -0.00029107, -0.00029107, ..., -0.00029107,\n",
       "         -0.00029107, -0.00029107]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisec_PDDP(A):\n",
    "    n = A.shape[1]\n",
    "    d = np.sum(A, axis=1)\n",
    "    A = A - d/n\n",
    "    print\n",
    "    u, s, vt = TruncatedSVD(A)\n",
    "    principal = vt.T[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable TruncatedSVD object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbisec_PDDP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_matrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36mbisec_PDDP\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m      3\u001b[0m d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(A, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m A \u001b[38;5;241m=\u001b[39m A \u001b[38;5;241m-\u001b[39m d\u001b[38;5;241m/\u001b[39mn\n\u001b[1;32m----> 5\u001b[0m u, s, vt \u001b[38;5;241m=\u001b[39m TruncatedSVD(A)\n\u001b[0;32m      6\u001b[0m principal \u001b[38;5;241m=\u001b[39m vt\u001b[38;5;241m.\u001b[39mT[:,\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable TruncatedSVD object"
     ]
    }
   ],
   "source": [
    "bisec_PDDP(dataset.doc_matrix)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
