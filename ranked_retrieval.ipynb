{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from load_data_json import LoadDataset \n",
    "from preprocess import VectorSpaceModel\n",
    "from preprocess_restart import VectorSpaceModel2\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse.linalg import svds, eigsh\n",
    "import ipyparallel as ipp\n",
    "from scipy.sparse import diags\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the dataset\n",
    "Functions to load the dataset and the given queries with associated relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dungl\\anaconda3\\envs\\IR_VectorSpaceModel\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = LoadDataset(\"./data/med/med.json\", \"./data/med/queries.json\", \"./data/med/qrels-treceval.txt\",\"med\")\n",
    "# vsm = VectorSpaceModel(dataset.doc_matrix, dataset.name)\n",
    "vsm = VectorSpaceModel2(dataset.doc_matrix, dataset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisec_PDDP(A, iter = 4):\n",
    "        # if np.all(indices==None):\n",
    "        #     A = self.A\n",
    "        # elif self.left:\n",
    "        #     A = self.A[indices, :]\n",
    "        # else:\n",
    "        #     A = self.A[:, indices]\n",
    "        \n",
    "        m, n = A.shape\n",
    "\n",
    "        # if m < n:\n",
    "        #     d = np.sum(A, axis=0)/m\n",
    "        #     q = np.zeros((m, iter))\n",
    "        #     v = np.random.rand(m)\n",
    "        # else:\n",
    "\n",
    "        d = np.sum(A, axis=1)/n\n",
    "        q = np.zeros((n, iter+1))\n",
    "        v = np.random.rand(n)\n",
    "        \n",
    "        q[:,0] = v/np.linalg.norm(v)\n",
    "        d = np.array(d).flatten()\n",
    "        \n",
    "        # lanczos\n",
    "        alpha = np.zeros(iter+1)\n",
    "        beta = np.zeros(iter+1)\n",
    "        \n",
    "        for i in range(iter):\n",
    "            # if m < n:\n",
    "            #     q_hat = A.T @ q[:,i] - np.sum(q[:,i]) * d\n",
    "            #     w = A @ q_hat - beta[i] * q[:,i-1] - np.full(m, q_hat @ d)\n",
    "            # else:\n",
    "            q_hat = A @ q[:,i] - np.sum(q[:,i]) * d\n",
    "            w = A.T @ q_hat - beta[i] * q[:,i-1] - np.full(n, q_hat @ d)\n",
    "\n",
    "            alpha[i] = w.dot(q[:,i])\n",
    "            w = w - alpha[i] * q[:,i]\n",
    "\n",
    "            beta[i+1] = np.linalg.norm(w)\n",
    "            if beta[i+1] == 0:\n",
    "                break\n",
    "            q[:,i+1] = w / beta[i+1]\n",
    "        # end lanczos\n",
    "        T = diags([alpha, beta, beta], [0, -1, 1]).toarray()\n",
    "        w, v = eigsh(T)\n",
    "        print(v.shape)\n",
    "        principal = q.dot(v[:,0])\n",
    "\n",
    "       \n",
    "        lo_bound = np.quantile(principal,.45)\n",
    "        up_bound = np.quantile(principal,.55)\n",
    "        left = np.where(principal < up_bound)[0]\n",
    "        right = np.where(principal > lo_bound)[0]\n",
    "        return left, right\n",
    "        # if np.all(indices==None):\n",
    "        #     return left, right\n",
    "        # else:\n",
    "        #     return indices[left], indices[right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dungl\\AppData\\Local\\Temp\\ipykernel_13236\\375018530.py:45: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "  w, v = eigsh(T)\n"
     ]
    }
   ],
   "source": [
    "l, r = bisec_PDDP(dataset.doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    2,    3,    4,    5,    6,    7,    9,   12,   14,   15,\n",
       "         18,   19,   21,   22,   25,   26,   27,   29,   30,   33,   34,\n",
       "         35,   38,   39,   41,   42,   44,   46,   47,   48,   49,   50,\n",
       "         51,   52,   53,   55,   56,   57,   61,   62,   63,   67,   71,\n",
       "         75,   79,   80,   81,   82,   83,   84,   87,   88,   89,   90,\n",
       "         95,   96,   97,   99,  100,  101,  102,  103,  104,  105,  106,\n",
       "        108,  109,  110,  111,  112,  113,  114,  115,  116,  117,  119,\n",
       "        121,  123,  124,  125,  133,  134,  135,  136,  137,  138,  139,\n",
       "        140,  141,  142,  145,  147,  148,  149,  151,  156,  157,  158,\n",
       "        160,  161,  163,  164,  166,  167,  168,  169,  170,  179,  180,\n",
       "        182,  183,  185,  186,  192,  193,  197,  198,  199,  200,  201,\n",
       "        202,  203,  205,  210,  211,  212,  214,  216,  224,  226,  227,\n",
       "        228,  230,  234,  235,  236,  237,  238,  239,  240,  241,  242,\n",
       "        243,  244,  252,  255,  257,  259,  262,  266,  267,  269,  270,\n",
       "        271,  275,  277,  278,  279,  287,  288,  289,  290,  293,  296,\n",
       "        297,  299,  300,  301,  303,  304,  305,  306,  307,  308,  309,\n",
       "        310,  311,  312,  313,  314,  315,  316,  318,  320,  321,  322,\n",
       "        326,  327,  328,  329,  330,  332,  336,  339,  343,  345,  348,\n",
       "        349,  350,  351,  352,  353,  355,  356,  357,  358,  359,  360,\n",
       "        362,  364,  365,  366,  367,  368,  369,  370,  371,  372,  373,\n",
       "        375,  376,  378,  379,  380,  382,  383,  384,  385,  386,  387,\n",
       "        388,  389,  392,  394,  400,  407,  408,  409,  410,  411,  412,\n",
       "        413,  415,  416,  417,  418,  419,  420,  421,  422,  435,  438,\n",
       "        439,  441,  442,  443,  444,  445,  450,  451,  453,  454,  455,\n",
       "        456,  457,  458,  459,  460,  463,  464,  465,  466,  467,  471,\n",
       "        473,  474,  475,  477,  478,  480,  482,  483,  484,  486,  488,\n",
       "        489,  490,  491,  492,  493,  496,  497,  498,  499,  500,  501,\n",
       "        502,  503,  504,  506,  507,  508,  509,  510,  511,  514,  515,\n",
       "        516,  521,  523,  524,  525,  527,  532,  534,  541,  542,  543,\n",
       "        549,  550,  551,  552,  556,  557,  558,  560,  562,  563,  564,\n",
       "        565,  573,  578,  584,  585,  587,  591,  593,  594,  597,  599,\n",
       "        603,  605,  608,  609,  611,  612,  614,  615,  617,  619,  620,\n",
       "        621,  623,  624,  626,  629,  630,  631,  632,  634,  635,  638,\n",
       "        639,  644,  645,  648,  649,  652,  654,  656,  658,  665,  670,\n",
       "        672,  674,  678,  681,  682,  684,  685,  686,  689,  690,  691,\n",
       "        693,  694,  695,  696,  697,  698,  700,  702,  706,  707,  708,\n",
       "        709,  710,  711,  712,  713,  715,  716,  717,  718,  720,  723,\n",
       "        724,  725,  728,  730,  731,  733,  734,  735,  736,  737,  740,\n",
       "        742,  743,  744,  745,  746,  747,  748,  750,  753,  754,  755,\n",
       "        758,  759,  762,  766,  767,  771,  774,  775,  776,  778,  783,\n",
       "        784,  790,  792,  793,  797,  800,  802,  804,  806,  808,  809,\n",
       "        810,  811,  812,  814,  817,  819,  820,  821,  823,  824,  826,\n",
       "        827,  828,  829,  832,  833,  834,  836,  837,  838,  839,  840,\n",
       "        843,  844,  846,  848,  850,  852,  853,  856,  858,  862,  863,\n",
       "        864,  865,  881,  882,  883,  884,  886,  887,  888,  890,  891,\n",
       "        893,  894,  897,  899,  900,  903,  904,  905,  906,  907,  909,\n",
       "        910,  913,  914,  915,  916,  917,  920,  921,  922,  925,  927,\n",
       "        929,  942,  944,  945,  946,  948,  949,  953,  956,  957,  959,\n",
       "        961,  962,  963,  964,  965,  966,  967,  968,  975,  977,  978,\n",
       "        980,  982,  983,  984,  986,  989,  992,  993,  996, 1001, 1003,\n",
       "       1006, 1007, 1009, 1011, 1012, 1013, 1015, 1016, 1018, 1019, 1020,\n",
       "       1021, 1022, 1024, 1028, 1029, 1030, 1031], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    4,    5,    6,    7,    9,   11,   15,   16,   17,   22,\n",
       "         24,   26,   27,   28,   29,   30,   31,   32,   33,   35,   38,\n",
       "         42,   44,   45,   48,   49,   50,   52,   55,   56,   62,   63,\n",
       "         65,   67,   73,   74,   75,   76,   81,   83,   85,   86,   87,\n",
       "         88,   91,   96,   99,  100,  101,  102,  103,  104,  105,  106,\n",
       "        109,  110,  111,  112,  113,  114,  115,  116,  117,  118,  119,\n",
       "        120,  121,  123,  124,  125,  131,  133,  135,  138,  139,  140,\n",
       "        145,  147,  148,  149,  150,  153,  156,  157,  158,  160,  173,\n",
       "        186,  187,  191,  199,  202,  203,  204,  215,  216,  217,  218,\n",
       "        219,  221,  223,  224,  225,  227,  228,  230,  237,  238,  239,\n",
       "        240,  241,  242,  244,  245,  246,  247,  248,  251,  252,  259,\n",
       "        260,  266,  267,  271,  272,  275,  278,  287,  292,  297,  302,\n",
       "        304,  305,  306,  307,  308,  309,  310,  311,  312,  313,  315,\n",
       "        316,  317,  318,  319,  320,  321,  322,  323,  324,  325,  326,\n",
       "        327,  328,  329,  330,  332,  337,  345,  347,  348,  349,  351,\n",
       "        352,  353,  354,  355,  356,  358,  360,  361,  362,  363,  364,\n",
       "        365,  367,  368,  369,  371,  373,  375,  376,  378,  379,  380,\n",
       "        382,  383,  384,  385,  386,  387,  388,  389,  390,  391,  392,\n",
       "        406,  408,  409,  410,  411,  412,  413,  414,  415,  417,  418,\n",
       "        419,  420,  421,  422,  438,  439,  440,  441,  442,  443,  444,\n",
       "        445,  446,  447,  448,  449,  451,  452,  453,  454,  455,  456,\n",
       "        457,  458,  459,  460,  461,  462,  463,  465,  466,  467,  482,\n",
       "        483,  484,  486,  487,  488,  489,  490,  491,  492,  493,  495,\n",
       "        497,  500,  513,  515,  517,  518,  519,  521,  523,  524,  525,\n",
       "        526,  527,  534,  536,  537,  544,  545,  546,  547,  548,  549,\n",
       "        550,  551,  552,  553,  554,  555,  557,  558,  559,  560,  561,\n",
       "        563,  564,  565,  566,  567,  568,  569,  570,  571,  572,  573,\n",
       "        574,  575,  576,  577,  578,  579,  580,  582,  583,  584,  585,\n",
       "        586,  587,  588,  589,  590,  591,  592,  593,  594,  596,  597,\n",
       "        598,  599,  600,  601,  602,  603,  604,  605,  606,  607,  608,\n",
       "        609,  610,  611,  612,  613,  614,  615,  616,  617,  618,  619,\n",
       "        620,  621,  622,  623,  624,  626,  630,  632,  634,  635,  645,\n",
       "        649,  654,  660,  661,  662,  672,  678,  683,  686,  687,  688,\n",
       "        689,  690,  691,  692,  693,  694,  695,  696,  697,  698,  700,\n",
       "        704,  705,  706,  708,  713,  718,  719,  724,  725,  739,  740,\n",
       "        742,  743,  744,  746,  750,  753,  758,  761,  767,  769,  770,\n",
       "        771,  772,  773,  774,  775,  776,  777,  778,  779,  780,  781,\n",
       "        782,  784,  785,  786,  787,  788,  789,  790,  791,  792,  794,\n",
       "        795,  796,  797,  798,  799,  800,  801,  802,  803,  804,  805,\n",
       "        806,  807,  808,  809,  810,  811,  812,  813,  814,  815,  816,\n",
       "        817,  818,  819,  820,  821,  825,  826,  829,  830,  831,  834,\n",
       "        837,  839,  840,  841,  843,  844,  845,  846,  847,  848,  852,\n",
       "        853,  857,  860,  862,  863,  864,  865,  866,  867,  868,  869,\n",
       "        870,  871,  872,  873,  874,  875,  876,  877,  878,  879,  880,\n",
       "        881,  882,  883,  884,  886,  887,  888,  889,  890,  891,  892,\n",
       "        893,  895,  896,  897,  901,  907,  913,  914,  915,  916,  917,\n",
       "        918,  919,  920,  921,  922,  923,  924,  925,  926,  927,  929,\n",
       "        931,  932,  943,  944,  945,  946,  947,  948,  949,  950,  951,\n",
       "        952,  953,  954,  956,  957,  961,  962,  968,  971,  981,  984,\n",
       "        986,  988,  989,  990,  991,  992,  993,  994,  995,  996,  997,\n",
       "        998,  999, 1000, 1001, 1002, 1003, 1005, 1006, 1009, 1013, 1018,\n",
       "       1019, 1022, 1026, 1028, 1030, 1031, 1032], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.0003274 , -0.0003274 , -0.0003274 , ..., -0.0003274 ,\n",
       "         -0.0003274 , -0.0003274 ],\n",
       "        [-0.00793646, -0.00793646,  0.04057048, ...,  0.02286208,\n",
       "         -0.00793646, -0.00793646],\n",
       "        [-0.00672568, -0.00672568,  0.04696494, ..., -0.00672568,\n",
       "         -0.00672568, -0.00672568],\n",
       "        ...,\n",
       "        [-0.00011589, -0.00011589, -0.00011589, ..., -0.00011589,\n",
       "         -0.00011589, -0.00011589],\n",
       "        [-0.00010179, -0.00010179, -0.00010179, ..., -0.00010179,\n",
       "         -0.00010179, -0.00010179],\n",
       "        [-0.00029107, -0.00029107, -0.00029107, ..., -0.00029107,\n",
       "         -0.00029107, -0.00029107]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisec_PDDP(A):\n",
    "    n = A.shape[1]\n",
    "    d = np.sum(A, axis=1)\n",
    "    A = A - d/n\n",
    "    print\n",
    "    u, s, vt = TruncatedSVD(A)\n",
    "    principal = vt.T[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable TruncatedSVD object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbisec_PDDP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_matrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36mbisec_PDDP\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m      3\u001b[0m d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(A, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m A \u001b[38;5;241m=\u001b[39m A \u001b[38;5;241m-\u001b[39m d\u001b[38;5;241m/\u001b[39mn\n\u001b[1;32m----> 5\u001b[0m u, s, vt \u001b[38;5;241m=\u001b[39m TruncatedSVD(A)\n\u001b[0;32m      6\u001b[0m principal \u001b[38;5;241m=\u001b[39m vt\u001b[38;5;241m.\u001b[39mT[:,\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable TruncatedSVD object"
     ]
    }
   ],
   "source": [
    "bisec_PDDP(dataset.doc_matrix)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
