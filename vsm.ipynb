{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General requests\n",
    "- comment the code\n",
    "- code able to run on Linux/macOS/unix-like environment\n",
    "- way to save and load the entire index from disk (avoid re-indexing when the program starts)\n",
    "- consider performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "Write an IR system using the Vector Space Model:\n",
    "1. able to answer free-form text queries \n",
    "2. allowing relevance feedback\n",
    "3. allowing the use of pseudo-relevance feedback\n",
    "4. evaluate it on a set of test queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Each document is seen as a vector with:\n",
    "- a component for each term in the dictionary\n",
    "- as elements the tf-idf $_{t,d}$ of the term $t$ in the document\n",
    "\n",
    "tf-idf $_{t,d}$ = 0 for all terms not in the document\n",
    "\n",
    "### To score a document\n",
    "Sum the tf-idf $_{t,d}$ values for all terms appeaing in $q$\n",
    "$$ Score(q,d) = \\sum_{t \\in q} tf-idf_{t,d} $$\n",
    "\n",
    "### Terms\n",
    "Elements of the canonical base of $ \\mathcal R ^n $ -> n = number of terms in the dictionary\n",
    "\n",
    "### Documents\n",
    "n-dimensional vector with each element the $tf-idf_{t,d}$\n",
    "\n",
    "Document vectors can be normalized and be replaced with a unit vector -> $ v(d) = \\frac{V(d)}{|V(d)|} $\n",
    "\n",
    "### Queries\n",
    "Unit vector with the non-zero components correspoding to the query terms\n",
    "\n",
    "### Cosine similarity \n",
    "1. to compare documents: $ sim(d_1, d_2) = \\frac{V(d_1) V(d_2)}{|V(d_1)| |V(d_2)|} $ -> the cosine of the angle formed by the two vectors\n",
    "\n",
    "2. to answer queries: $ score(q,d_1)=v(q) v(d_1) \\equiv score(q,d_1)=v(q) v(d_1) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MED dataset - Medline Documents Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def load_docs(corpus):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with keys the docID and as \n",
    "    values the list of terms in the document.\n",
    "    \"\"\"\n",
    "    arts = []\n",
    "    with open(corpus, \"r\") as f:\n",
    "        t = []\n",
    "        r = False\n",
    "        for row in f:\n",
    "            if row.startswith(\".W\"):\n",
    "                r = True\n",
    "                continue\n",
    "            if row.startswith(\".I\"):\n",
    "                if t != []:\n",
    "                    arts.append(t)\n",
    "                t = []\n",
    "                r = False\n",
    "                # docid = int(row[3:].replace(\"\\n\", \"\"))\n",
    "            if r:\n",
    "                row = re.sub(r'[^a-zA-Z\\s]+', '', row)\n",
    "                t += row.split()\n",
    "    return arts\n",
    "\n",
    "def load_queries(query_file):\n",
    "    \"\"\"\"\n",
    "    Returns a dictionary of lists, with keys the queryID \n",
    "    and as values a list of terms occurring in the query.\n",
    "    \"\"\"\n",
    "    q = dict()\n",
    "    with open(query_file, \"r\") as f:\n",
    "        t = []\n",
    "        r = False\n",
    "        for row in f:\n",
    "            if row.startswith(\".W\"):\n",
    "                r = True\n",
    "                continue\n",
    "            if row.startswith(\".I\"):\n",
    "                if t != []:\n",
    "                    q[qid] = t\n",
    "                t = []\n",
    "                r = False\n",
    "                qid = int(row[3:].replace(\"\\n\", \"\"))\n",
    "            if r:\n",
    "                row = re.sub(r'[^a-zA-Z\\s]+', '', row)\n",
    "                t += row.split()\n",
    "    return q\n",
    "\n",
    "def load_relevance(relevance_file):\n",
    "    \"\"\"\"\n",
    "    Returns a dictionary of lists, with keys the queryID and \n",
    "    as values the list of documents relevant to that query.\n",
    "    \"\"\"\n",
    "    rel = dict()\n",
    "    with open(relevance_file, \"r\") as f:\n",
    "        t = []\n",
    "        for row in f:\n",
    "            r = row.split(\" \")\n",
    "            qid = int(r[0])\n",
    "            rel[qid] = rel.get(qid, []) + [int(r[2])]\n",
    "\n",
    "    return rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, Counter\n",
    "from math import log, sqrt\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_docs(\"./cran_data/cran.all.1400\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the positional index: returns a dictionary in which for each term we have a dictionary with as keys the docIDs (integers referring to one document) and as values a list with the position of the term in the document.\n",
    "\n",
    "$ \\texttt{ \\{\"RUSSIA\" : \\{0:[1,6,35], 10:[6,22,105]\\}, \"COLD\" : \\{12:[6], 100:[2]\\}\\} } $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [[\"ciao\", \"come\", \"va\", \"ciao\"], [\"tutto\", \"bene\", \"te\"], [\"random\", \"ciao\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(corpus):\n",
    "    \"\"\"\n",
    "    Builds an inverted index.\n",
    "    Returns a dictionary with terms as keys and for each term it stores \n",
    "    a list as value, with docIDs of the documents contianing the term.\n",
    "    \"\"\"\n",
    "    idx = dict()\n",
    "    for docid in range(len(corpus)):  # for each document in the corpus\n",
    "        for pos, t in enumerate(corpus[docid]):  # for each term in the document\n",
    "            idx[t] = idx.get(t, set())\n",
    "            idx[t].add(docid)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ciao': {0, 2},\n",
       " 'come': {0},\n",
       " 'va': {0},\n",
       " 'tutto': {1},\n",
       " 'bene': {1},\n",
       " 'te': {1},\n",
       " 'random': {2}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_index(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the inverse document frequency for each term. Returns a dictionary with terms as keys and IDF as values.\n",
    "$ \\texttt{ \\{\"THE\":0.0, \"REVENUES\": 1.6094379124341003\\}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_doc_freq(p_idx, n_docs):\n",
    "    idf = dict()\n",
    "    for t in p_idx.keys():\n",
    "        idf[t] = log( n_docs / len(p_idx[t]) )\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ciao': 0.4054651081081644,\n",
       " 'come': 1.0986122886681098,\n",
       " 'va': 1.0986122886681098,\n",
       " 'tutto': 1.0986122886681098,\n",
       " 'bene': 1.0986122886681098,\n",
       " 'te': 1.0986122886681098,\n",
       " 'random': 1.0986122886681098}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_doc_freq(inverted_index(corpus), len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the TF-IDF for each term and each document. Returns a dictionary with docIDs as keys and as values a dictionary with terms as keys and as values the corresponding tf-idf for the specific term in the specific document.\n",
    "\n",
    "In this way, each document is seen as a n-dimensional vector, with n being the number of terms in the dictionary.\n",
    "\n",
    "$ \\texttt{ \\{0:\\{\"THE\": 0.0\\}, 10:\\{\"THE\": 1.6094379124341003\\}\\} } $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectors(docs, p_idx):\n",
    "    n_docs = len(docs)\n",
    "    n_terms = len(p_idx.keys())\n",
    "    vocab = list(p_idx.keys())\n",
    "    vecs = np.zeros((n_docs, n_terms))\n",
    "    idf = inverse_doc_freq(p_idx, n_docs)\n",
    "\n",
    "    for docid in range(n_docs):\n",
    "        count = Counter(docs[docid])\n",
    "\n",
    "        for t in vocab:\n",
    "            if t in docs[docid]:\n",
    "                ind = vocab.index(t)\n",
    "                vecs[docid][ind] = idf[t] * count[t]\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81093022, 1.09861229, 1.09861229, 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.09861229, 1.09861229,\n",
       "        1.09861229, 0.        ],\n",
       "       [0.40546511, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.09861229]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors(corpus, inverted_index(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tf_idf(docs, p_idx):\n",
    "#     tfidf = {}\n",
    "#     n_docs = len(docs)\n",
    "#     idf = inverse_doc_freq(p_idx, n_docs)\n",
    "#     for docid in range(len(docs)):  #for each document\n",
    "#         doc_vector = {}  # we store for each term in the document the tfidf \n",
    "#                          # and for those not in the document a 0\n",
    "#         count = Counter(docs[docid])\n",
    "#         for t in p_idx.keys():\n",
    "#             if t in docs[docid]:\n",
    "#                 doc_vector[t] = idf[t] * count[t]\n",
    "#             else:\n",
    "#                 doc_vector[t] = 0\n",
    "#         tfidf[docid] = doc_vector\n",
    "#     return tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert a query, given as a free-form text, to a n-dimensional vector, with n being the number of terms in the dictionary, with 1 if the term is present in the query and 0 otherwise.\n",
    "\n",
    "$ \\texttt{query = \"revenues tree\"} $\n",
    "\n",
    "$ \\texttt{ \\{\"THE\":0, \"REVENUES\":1\\} } $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_queries(\"./cran_data/cran.qry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = \"ciao sono elena come stai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector(query, p_idx):\n",
    "    q = query.lower().split(\" \")\n",
    "    n_terms = len(p_idx.keys())\n",
    "    vocab = list(p_idx.keys())\n",
    "    vec = np.zeros(n_terms)\n",
    "\n",
    "    for t in vocab:\n",
    "        if t in q:\n",
    "            ind = vocab.index(t)\n",
    "            vec[ind] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vector(queries, inverted_index(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def query_as_vector(q, p_idx):\n",
    "#     # q = q.lower().split(\" \")\n",
    "#     q_vec = {}\n",
    "#     count = Counter(q)\n",
    "#     # l = len(q)\n",
    "#     idf = inverse_doc_freq(p_idx, n_docs)\n",
    "#     for t in list(p_idx.keys()):\n",
    "#         if t in q:\n",
    "#             # q_vec[t] = 1\n",
    "#             q_vec[t] = count[t] * idf[t]\n",
    "#         else:\n",
    "#             q_vec[t] = 0\n",
    "#     return q_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the relevance score for each document given a query. The score is computed as the cosine similarity between the query vector and the document vector. It returns a dictionary with the docIDs as keys and the relevance score as values.\n",
    "\n",
    "$ \\texttt{ \\{0:0.0, 1:0.03272921367166952\\} } $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_scores(query, p_idx, docs):\n",
    "    scores = dict()  # for each document we store the cosine similarity\n",
    "                     # between the query and the document\n",
    "    query_terms = query.split(\" \")\n",
    "    q = query_vector(query, p_idx)\n",
    "    q_length = sqrt(sum(q**2))\n",
    "\n",
    "    vocab = list(p_idx.keys())\n",
    "    tfidf = tfidf_vectors(docs, p_idx)\n",
    "\n",
    "    for docid in range(len(docs)):\n",
    "        d = tfidf[docid,]\n",
    "        d_length = sqrt(sum(d**2))\n",
    "        cos_sim = 0\n",
    "        for t in query_terms:\n",
    "            if t in vocab:\n",
    "                idx = vocab.index(t)\n",
    "                cos_sim += (d[idx] * q[idx])\n",
    "        \n",
    "        if cos_sim == 0:\n",
    "            scores[docid] = 0\n",
    "        else:\n",
    "            scores[docid] = cos_sim / (q_length * d_length)\n",
    "    \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7704397233076248, 1: 0, 2: 0.24482975009584626}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_scores(queries, inverted_index(corpus), corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to return the k most relevant documents given a query.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_space_model(query, k, corpus):\n",
    "    # for a given query and the tfidf matrix, \n",
    "    # we return the top k documents\n",
    "    # relevant for the given query\n",
    "\n",
    "    index = inverted_index(corpus)\n",
    "\n",
    "    scores = relevance_scores(query, index, corpus)\n",
    "    sorted_value = OrderedDict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
    "    topk = {key : sorted_value[key] for key in list(sorted_value)[:k] if sorted_value[key]!=0}\n",
    "\n",
    "    return topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7704397233076248}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_docs = vector_space_model(queries, 1, corpus)\n",
    "topk_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevance and pseudo-relevance feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback given as a query and a list of `(docID, feedback_value)` with 0. means irrelevant and 1. means relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_docs = [1]\n",
    "nrel_docs = [0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf_vectors(corpus, inverted_index(corpus))\n",
    "vocab = list(inverted_index(corpus).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_feedback_rocchio(rel_docs, nrel_docs, query, tfidf, vocab, alpha=1, beta=0.75, gamma=0.15):\n",
    "    query = query_vector(query, inverted_index(corpus))\n",
    "    q_opt = np.zeros(len(vocab))\n",
    "    for t in vocab:\n",
    "        idx = vocab.index(t)\n",
    "        r = 0\n",
    "        for docid in rel_docs:\n",
    "            r += tfidf[docid,].sum()\n",
    "        r /= len(rel_docs)\n",
    "\n",
    "        n = 0\n",
    "        if len(nrel_docs) != 0:\n",
    "            for docid in nrel_docs:\n",
    "                n += tfidf[docid,].sum()\n",
    "            n /= len(nrel_docs)\n",
    "        else:\n",
    "            gamma = 0\n",
    "\n",
    "        opt = alpha*query[idx] + beta*r - gamma*n\n",
    "        if opt > 0:\n",
    "            q_opt[idx] = opt\n",
    "\n",
    "    return q_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_opt = relevance_feedback_rocchio(rel_docs, nrel_docs, queries, tfidf, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_relevance_feedback(query, tfidf, vocab, k=10):\n",
    "    rel_docs = list(vector_space_model(query, k, corpus).keys())\n",
    "    q_opt = relevance_feedback_rocchio(rel_docs=rel_docs, nrel_docs=[], query=query, tfidf=tfidf, vocab=vocab, gamma=0)\n",
    "    return q_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.2561161, 3.2561161, 2.2561161, 2.2561161, 2.2561161, 2.2561161,\n",
       "       2.2561161])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_relevance_feedback(queries, tfidf, vocab, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(k):\n",
    "    \"\"\"To generate list of precision values for each query for given value of k\n",
    "    \n",
    "    Arguments:\n",
    "        k {[type]} -- number of top documents to be retrieved\n",
    "    \n",
    "    Returns:\n",
    "        list -- list of precision values for each query\n",
    "    \"\"\"\n",
    "    precision = []\n",
    "    for i in range(len(queries)):\n",
    "        \n",
    "        # Number of relevant documents retrieved\n",
    "        a = intersection(list_of_docs(k)[i][1].tolist(), query_rel[i])\n",
    "        \n",
    "        # Total number of documents retrieved\n",
    "        b = k\n",
    "        p = a / b\n",
    "        precision.append(p)\n",
    "    return precision\n",
    "\n",
    "# for top 100 docs\n",
    "calculate_precision(no_of_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(k):\n",
    "    \"\"\"To generate list of recall values for each query for given value of k\n",
    "    \n",
    "    Arguments:\n",
    "        k {integer} -- number of top documents to be retrieved \n",
    "    \n",
    "    Returns:\n",
    "        list -- list of recall values for each query\n",
    "    \"\"\"\n",
    "    \n",
    "    recall = []\n",
    "    for i in range(len(queries)):\n",
    "        \n",
    "        # Number of relevant documents retrieved\n",
    "        a = intersection(list_of_docs(k)[i][1].tolist(), query_rel[i])\n",
    "        \n",
    "        # Total number of relevant documents\n",
    "        b = len(query_rel[i])\n",
    "        r = a / b\n",
    "        recall.append(r)\n",
    "    return recall   \n",
    "# for top 100 docs\n",
    "calculate_recall(no_of_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    \"\"\"To count number of common items between 2 lists\n",
    "    \n",
    "    Arguments:\n",
    "        lst1 {list} -- list 1\n",
    "        lst2 {list} -- list 2\n",
    "    \n",
    "    Returns:\n",
    "        integer -- number of common items between list 1 & list 2 \n",
    "    \"\"\"\n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return len(lst3) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
